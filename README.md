### A Gentle Introduction to Feed-Forward Neural Networks and Implementing it from Scratch Using NumPy
Welcome to the repository for building a Feed-Forward Neural Network (FFNN) from scratch using NumPy. This project provides a detailed explanation and implementation of a FFNN, including the mathematical concepts and programming techniques involved.

- Table of Contents
- Introduction
- Structure of a Feed-Forward Neural Network
- Mathematical Formulation
- Setting Up the Environment
- Implementation
- Training the Neural Network
- Conclusion

### Introduction
A Feed-Forward Neural Network is the simplest type of artificial neural network, where information moves in only one direction: forwardâ€”from the input nodes, through the hidden nodes (if any), and to the output nodes. This structure means that there are no cycles or loops in the network.

Structure of a Feed-Forward Neural Network
Input Layer: Neurons that receive the input data. Each neuron represents a feature of the input data.
Hidden Layers: One or more hidden layers that learn complex patterns in the data. Each neuron in a hidden layer applies a weighted sum of inputs followed by a non-linear activation function.
Output Layer: Provides the final output of the network. The number of neurons corresponds to the number of classes in a classification problem or the number of outputs in a regression problem.

To learn more: https://medium.com/p/b13f2ea7ac73/
